{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = {\n",
    "\n",
    "    # Parametrization bellow cannot be changed\n",
    "    \"lanes_count\" : 10, # The environment must always have 10 lanes\n",
    "    \"vehicles_count\": 50, # The environment must always have 50 other vehicles\n",
    "    \"duration\": 120,  # [s] The environment must terminate never before 120 seconds\n",
    "    \"other_vehicles_type\": \"highway_env.vehicle.behavior.IDMVehicle\", # This is the policy of the other vehicles\n",
    "    \"initial_spacing\": 2, # Initial spacing between vehicles needs to be at most 2\n",
    "\n",
    "    # Refer to refer to https://highway-env.farama.org/actions/ to change action space type\n",
    "    \"action\": {\n",
    "        \"type\": \"DiscreteMetaAction\",\n",
    "    },\n",
    "\n",
    "    # Parameterization bellow can be changed (as it refers mostly to the reward system)\n",
    "    # \"collision_reward\": -10,  # The reward received when colliding with a vehicle. (Can be changed)\n",
    "    # \"reward_speed_range\": [20, 30],  # [m/s] The reward for high speed is mapped linearly from this range to [0, HighwayEnv.HIGH_SPEED_REWARD]. (Can be changed)\n",
    "    \"simulation_frequency\": 15, #15,  # [Hz] (Can be changed)\n",
    "    \"policy_frequency\": 5, #5,  # [Hz] (Can be changed)\n",
    "\n",
    "    \"collision_reward\": -100,  # The reward received when colliding with a vehicle.\n",
    "    \"right_lane_reward\": 8,  # The reward received when driving on the right-most lanes, linearly mapped to\n",
    "    # zero for other lanes.\n",
    "    \"high_speed_reward\": 5,  # The reward received when driving at full speed, linearly mapped to zero for\n",
    "    # lower speeds according to config[\"reward_speed_range\"].\n",
    "    \"lane_change_reward\": -1,  # The reward received at each lane change action.\n",
    "    \"reward_speed_range\": [20, 30],\n",
    "    \"normalize_reward\": False,  # True to normalize the reward to the range [-1, 0], False to return the original reward.\n",
    "    \n",
    "    # Parameters defined bellow are purely for visualiztion purposes! You can alter them as you please\n",
    "    \"screen_width\": 800,  # [px]\n",
    "    \"screen_height\": 600,  # [px]\n",
    "    \"centering_position\": [0.5, 0.5],\n",
    "    \"scaling\": 5,\n",
    "    \"show_trajectories\": True,\n",
    "    \"render_agent\": True,\n",
    "    \"offscreen_rendering\": False\n",
    "}\n",
    "\n",
    "default_config = configuration.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeToCollisionVec:\n",
    "    def __init__(self, \n",
    "                num_envs=1, \n",
    "                horizon=5,\n",
    "                policy_frequency=5,\n",
    "                simulation_frequency=15,\n",
    "                high_speed_reward=10,\n",
    "                right_lane_reward=10,\n",
    "                lane_change_reward=-1,\n",
    "                obs_type='speed-restricted',\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Constructor for the TimeToCollisionVec class.\n",
    "        Args:\n",
    "            num_envs: Number of parallel environments to run.\n",
    "            horizon: The number of timesteps to look ahead for the TimeToCollision observation.\n",
    "            policy_frequency: The frequency at which the policy is evaluated.\n",
    "            simulation_frequency: The frequency at which the simulation is run.\n",
    "            high_speed_reward: The reward given for driving at high speed.\n",
    "            right_lane_reward: The reward given for driving in the right lane.\n",
    "            lane_change_reward: The reward given for changing lanes.\n",
    "            obs_type: The type of observation to use. Choose from 'normal' or 'speed-restricted'\n",
    "                'normal': The normal TimeToCollision observation (x3 different speeds the car could be at)\n",
    "                'speed-restricted': Only one of the TimeToCollision observations is used (the speed the car is currently at) (less complex observation space)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.config = default_config.copy()\n",
    "        self.config[\"observation\"] =  {\n",
    "                \"type\": \"TimeToCollision\",\n",
    "                \"horizon\": horizon}\n",
    "        self.horizon = horizon\n",
    "\n",
    "        self.config.update({\n",
    "            \"policy_frequency\": policy_frequency,\n",
    "            \"simulation_frequency\": simulation_frequency,\n",
    "            \"high_speed_reward\": high_speed_reward,\n",
    "            \"right_lane_reward\": right_lane_reward,\n",
    "            \"lane_change_reward\": lane_change_reward\n",
    "        })\n",
    "        \n",
    "        self.num_envs = num_envs\n",
    "        self.obs_type = obs_type\n",
    "\n",
    "        with gym.make(\"highway-fast-v0\", config=self.config) as env:\n",
    "            self.env = gym.vector.AsyncVectorEnv([lambda: env for _ in range(num_envs)])\n",
    "            self.obs_space_shape = env.observation_space.shape if obs_type == 'normal' else env.observation_space.shape[1:]\n",
    "            self.action_space_size = env.action_space.n\n",
    "\n",
    "    def get_speeds(self):\n",
    "        return [car.speed_index for car in self.env.get_attr('vehicle')]\n",
    "    \n",
    "    def get_state(self, obs):\n",
    "        if self.obs_type == 'normal':\n",
    "            return obs\n",
    "        else:\n",
    "            speed_indices = self.get_speeds()\n",
    "            return np.array([obs[i][speed_indices[i]] for i in range(self.num_envs)])\n",
    "    \n",
    "    def reset(self, seeds=None):\n",
    "        if seeds is None:\n",
    "            seeds = [np.random.randint(100000) for _ in range(self.num_envs)]\n",
    "        obs, info = self.env.reset(seed=seeds)\n",
    "        return self.get_state(obs)\n",
    "    \n",
    "    def step(self, actions):\n",
    "        obs, rewards, dones, truncates, info = self.env.step(actions)\n",
    "        return self.get_state(obs), np.array(rewards), np.array(dones), np.array(truncates)\n",
    "    \n",
    "    def close(self):\n",
    "        self.env.close()    \n",
    "\n",
    "    def action_space_sample(self):  \n",
    "        return self.env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttcvec = TimeToCollisionVec(num_envs=2, obs_type='speed-restricted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ttcvec.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(-1, np.prod(a.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 25)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS:  7.032930637310061\n"
     ]
    }
   ],
   "source": [
    "ttc_test = TimeToCollision(policy_frequency=5, simulation_frequency=15)\n",
    "ttc_test.test_env(sleep_time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS:  5.217737200501177\n"
     ]
    }
   ],
   "source": [
    "ttc_test_fast = TimeToCollision(policy_frequency=4, simulation_frequency=20)\n",
    "ttc_test_fast.test_env(sleep_time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeToCollision:\n",
    "    def __init__(self, horizon=5,\n",
    "                policy_frequency=1,\n",
    "                simulation_frequency=10,\n",
    "                render_mode=None):\n",
    "\n",
    "        self.config = default_config.copy()\n",
    "        self.config[\"observation\"] =  {\n",
    "        \"type\": \"TimeToCollision\",\n",
    "        \"horizon\": horizon}\n",
    "        self.horizon = horizon\n",
    "        \n",
    "        self.config['policy_frequency'] = policy_frequency\n",
    "        self.config['simulation_frequency'] = simulation_frequency\n",
    "\n",
    "        with gym.make(\"highway-fast-v0\", config=self.config, render_mode=render_mode) as env:\n",
    "            self.env = env\n",
    "            # self.OBSERVATION_SPACE_VALUES = env.observation_space.shape[1:]\n",
    "            self.OBSERVATION_SPACE_VALUES = env.observation_space.shape\n",
    "            self.ACTION_SPACE_SIZE = env.action_space.n\n",
    "    \n",
    "    def get_state(self): \n",
    "        grid = self.env.get_wrapper_attr('vehicle').speed_index\n",
    "        # return self.current_obs[grid]\n",
    "        return self.current_obs\n",
    "    \n",
    "    def reset(self, seed='random'):\n",
    "        if seed == 'random':\n",
    "            seed = np.random.randint(100000)\n",
    "        self.current_obs, info = self.env.reset(seed=seed)\n",
    "        return self.get_state()\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.current_obs, reward, done, truncated, info = self.env.step(action)\n",
    "        return self.get_state(), reward, done, truncated\n",
    "    \n",
    "    def close(self): \n",
    "        self.env.close()\n",
    "\n",
    "    def test_env(self, sleep_time=1):\n",
    "        with gym.make(\"highway-v0\", config=self.config, render_mode=None) as env:\n",
    "            self.env = env\n",
    "            step = 0\n",
    "            obs = env.reset()\n",
    "            for _ in range(1000):\n",
    "                action = env.action_space.sample()\n",
    "                self.current_obs, reward, done, truncated, info = env.step(action)\n",
    "                print(self.get_state(), reward)\n",
    "                done = done | truncated\n",
    "                if done:\n",
    "                    break\n",
    "                step += 1\n",
    "                time.sleep(sleep_time)\n",
    "        \n",
    "\n",
    "ttc = TimeToCollision(horizon=5, \n",
    "                      policy_frequency=4, \n",
    "                      simulation_frequency=20)\n",
    "# ttc.test_env(sleep_time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Activation, Flatten\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "REPLAY_MEMORY_SIZE = 50_000\n",
    "MODEL_NAME = \"2x16\"\n",
    "MIN_REPLAY_MEMORY_SIZE = 1_000\n",
    "MINIBATCH_SIZE = 64\n",
    "DISCOUNT = 0.99 \n",
    "UPDATE_TARGET_EVERY = 5\n",
    "EPISODES = 1_000\n",
    "MIN_REWARD = -100\n",
    "epsilon = 1  # not a constant, going to be decayed\n",
    "EPSILON_DECAY = 0.9975\n",
    "MIN_EPSILON = 0.001\n",
    "EVAL_FREQUENCY = 25\n",
    "\n",
    "if not os.path.isdir('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, env): \n",
    "        self.env = env\n",
    "        # Main model - what gets trained every step\n",
    "        self.model = self.create_model()\n",
    "\n",
    "        # Target model - what we predict every step\n",
    "        self.target_model = self.create_model()\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "        self.replay_memory = deque(maxlen=REPLAY_MEMORY_SIZE)\n",
    "        \n",
    "        # self.tensorboard = ModifiedTensorBoard(log_dir=f\"logs/{MODEL_NAME}-{int(time.time())}\")\n",
    "        self.target_update_counter = 0\n",
    "\n",
    "\n",
    "    def create_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(16, (2, 2), input_shape=self.env.OBSERVATION_SPACE_VALUES))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Flatten()) \n",
    "        model.add(Dense(64))\n",
    "        model.add(Dense(64))\n",
    "\n",
    "        model.add(Dense(self.env.ACTION_SPACE_SIZE, activation='linear'))  # ACTION_SPACE_SIZE = how many choices\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "        return model \n",
    "    \n",
    "    def update_replay_memory(self, transition):\n",
    "        self.replay_memory.append(transition)\n",
    "\n",
    "    def get_qs(self, state):\n",
    "        return self.model.predict(np.array(state).reshape(-1, *state.shape), verbose=0)[0]\n",
    "\n",
    "    def train(self, terminal_state): \n",
    "        if len(self.replay_memory) < MIN_REPLAY_MEMORY_SIZE:\n",
    "            return \n",
    "        \n",
    "        minibatch = random.sample(self.replay_memory, MINIBATCH_SIZE)\n",
    "\n",
    "        current_states = np.array([transition[0] for transition in minibatch])\n",
    "        current_qs_list = self.model.predict(current_states, verbose=0)                      # The model that gets trained every step\n",
    "\n",
    "        new_current_states = np.array([transition[3] for transition in minibatch])\n",
    "        future_qs_list = self.target_model.predict(new_current_states, verbose=0)              # The model that doesn't get trained every step\n",
    "\n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        for index, (current_state, action, reward, new_current_state, done) in enumerate(minibatch):\n",
    "            if not done:\n",
    "                max_future_q = np.max(future_qs_list[index])\n",
    "                new_q = reward + DISCOUNT * max_future_q\n",
    "            else:\n",
    "                new_q = reward\n",
    "\n",
    "            current_qs = current_qs_list[index]\n",
    "            # Update the q value for the action taken\n",
    "            current_qs[action] = new_q\n",
    "\n",
    "            X.append(current_state)\n",
    "            y.append(current_qs)\n",
    "        \n",
    "        self.model.fit(np.array(X), np.array(y), batch_size=MINIBATCH_SIZE, verbose=0, shuffle=False, \n",
    "                       #callbacks=[self.tensorboard] if terminal_state else None\n",
    "                       )\n",
    "\n",
    "        # Update target network counter every episode\n",
    "        if terminal_state:\n",
    "            self.target_update_counter += 1\n",
    "\n",
    "        # If counter reaches set value, update target network with weights of main network\n",
    "        if self.target_update_counter > UPDATE_TARGET_EVERY:\n",
    "            self.target_model.set_weights(self.model.get_weights())\n",
    "            self.target_update_counter = 0\n",
    "\n",
    "\n",
    "    def evaluate(self, agent, n_games=3, t_max=1000, render=True, verbose=True):\n",
    "        sim_freq, pol_freq, horizon = self.env.config['simulation_frequency'], self.env.config['policy_frequency'], self.env.horizon\n",
    "        render_mode = 'human' if render else None\n",
    "        ttc_env = TimeToCollision(policy_frequency=pol_freq, simulation_frequency=sim_freq, horizon=horizon, render_mode=render_mode)\n",
    "\n",
    "        print('Evaluating...') if verbose else None\n",
    "        rewards = []\n",
    "        for i in tqdm(range(n_games)):\n",
    "            cum_reward = 0\n",
    "            steps, done = 0, False\n",
    "            current_state = ttc_env.reset(seed=np.random.randint(100000))\n",
    "            while not done and steps < t_max: \n",
    "                # Get next action \n",
    "                next_action = np.argmax(agent.get_qs(current_state))\n",
    "                current_state, reward, done, truncated = ttc_env.step(next_action)\n",
    "                done = done | truncated\n",
    "                cum_reward += reward\n",
    "                steps += 1\n",
    "            rewards.append(cum_reward)\n",
    "\n",
    "        ttc_env.close()\n",
    "        return np.mean(rewards)\n",
    "\n",
    "\n",
    "\n",
    "ttc = TimeToCollision(horizon=5, \n",
    "                      policy_frequency=4, \n",
    "                      simulation_frequency=20)\n",
    "\n",
    "agent = DQNAgent(ttc)\n",
    "\n",
    "ep_rewards = []\n",
    "mean_rw_history = []\n",
    "step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode = 250, episode_rewards = 445.919, epsilon = 0.52032\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m     action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, ttc\u001b[38;5;241m.\u001b[39mACTION_SPACE_SIZE)\n\u001b[1;32m---> 14\u001b[0m new_state, reward, done, truncate \u001b[38;5;241m=\u001b[39m \u001b[43mttc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m done \u001b[38;5;241m=\u001b[39m done \u001b[38;5;241m|\u001b[39m truncate\n\u001b[0;32m     17\u001b[0m episode_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Cell \u001b[1;32mIn[11], line 34\u001b[0m, in \u001b[0;36mTimeToCollision.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_obs, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_state(), reward, done, truncated\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:51\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\highway_env\\envs\\common\\abstract.py:235\u001b[0m, in \u001b[0;36mAbstractEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe road and vehicle must be initialized in the environment implementation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy_frequency\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 235\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_simulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    237\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_type\u001b[38;5;241m.\u001b[39mobserve()\n\u001b[0;32m    238\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reward(action)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\highway_env\\envs\\common\\abstract.py:257\u001b[0m, in \u001b[0;36mAbstractEnv._simulate\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \\\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanual_control\u001b[39m\u001b[38;5;124m\"\u001b[39m] \\\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimulation_frequency\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy_frequency\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_type\u001b[38;5;241m.\u001b[39mact(action)\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroad\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimulation_frequency\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\highway_env\\road\\road.py:324\u001b[0m, in \u001b[0;36mRoad.act\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decide the actions of each entity on the road.\"\"\"\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vehicle \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvehicles:\n\u001b[1;32m--> 324\u001b[0m     \u001b[43mvehicle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\highway_env\\vehicle\\behavior.py:100\u001b[0m, in \u001b[0;36mIDMVehicle.act\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     97\u001b[0m action[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msteering\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(action[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msteering\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMAX_STEERING_ANGLE, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMAX_STEERING_ANGLE)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Longitudinal: IDM\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m front_vehicle, rear_vehicle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneighbour_vehicles\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlane_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m action[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macceleration\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macceleration(ego_vehicle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    102\u001b[0m                                            front_vehicle\u001b[38;5;241m=\u001b[39mfront_vehicle,\n\u001b[0;32m    103\u001b[0m                                            rear_vehicle\u001b[38;5;241m=\u001b[39mrear_vehicle)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# When changing lane, check both current and target lanes\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\highway_env\\road\\road.py:361\u001b[0m, in \u001b[0;36mRoad.neighbour_vehicles\u001b[1;34m(self, vehicle, lane_index)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvehicles \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjects:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vehicle \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, Landmark):  \u001b[38;5;66;03m# self.network.is_connected_road(v.lane_index,\u001b[39;00m\n\u001b[0;32m    360\u001b[0m         \u001b[38;5;66;03m# lane_index, same_lane=True):\u001b[39;00m\n\u001b[1;32m--> 361\u001b[0m         s_v, lat_v \u001b[38;5;241m=\u001b[39m \u001b[43mlane\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_coordinates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lane\u001b[38;5;241m.\u001b[39mon_lane(v\u001b[38;5;241m.\u001b[39mposition, s_v, lat_v, margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    363\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\highway_env\\road\\lane.py:189\u001b[0m, in \u001b[0;36mStraightLane.local_coordinates\u001b[1;34m(self, position)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlocal_coordinates\u001b[39m(\u001b[38;5;28mself\u001b[39m, position: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m    188\u001b[0m     delta \u001b[38;5;241m=\u001b[39m position \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart\n\u001b[1;32m--> 189\u001b[0m     longitudinal \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdirection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m     lateral \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(delta, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirection_lateral)\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(longitudinal), \u001b[38;5;28mfloat\u001b[39m(lateral)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for episode in tqdm(range(1, EPISODES+1), unit='episode'):\n",
    "    # agent.tensorboard.step = episode\n",
    "\n",
    "    episode_reward = 0\n",
    "    current_state = ttc.reset(seed=np.random.randint(100000))\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        if np.random.random() > epsilon:\n",
    "            action = np.argmax(agent.get_qs(current_state))\n",
    "        else:\n",
    "            action = np.random.randint(0, ttc.ACTION_SPACE_SIZE)\n",
    "\n",
    "        new_state, reward, done, truncate = ttc.step(action)\n",
    "        done = done | truncate\n",
    "\n",
    "        episode_reward += reward\n",
    "\n",
    "        # if SHOW_PREVIEW and not episode % AGGREGATE_STATS_EVERY:\n",
    "        #     ttc.render()\n",
    "\n",
    "        agent.update_replay_memory((current_state, action, reward, new_state, done))\n",
    "        agent.train(done)\n",
    "\n",
    "        current_state = new_state\n",
    "        step += 1\n",
    "\n",
    "    # Append episode reward to a list and log stats (every given number of episodes)\n",
    "    ep_rewards.append(episode_reward)\n",
    "\n",
    "    if episode % EVAL_FREQUENCY == 0:\n",
    "        # eval the agent\n",
    "        mean_rw_history.append(agent.evaluate(\n",
    "            agent, n_games=3, t_max=1000)\n",
    "        )\n",
    "\n",
    "        clear_output(True)\n",
    "\n",
    "        print(\"episode = %i, episode_rewards = %.3f, epsilon = %.5f\" %\n",
    "              (episode, episode_reward, epsilon))\n",
    "\n",
    "        plt.figure(figsize=[8, 5])\n",
    "        plt.title(\"Mean reward per episode\")\n",
    "        plt.plot(mean_rw_history)\n",
    "        plt.grid()\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    # Decay epsilon\n",
    "    if epsilon > MIN_EPSILON:\n",
    "        epsilon *= EPSILON_DECAY\n",
    "        epsilon = max(MIN_EPSILON, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f4acf9af634e5f8be7a4cac74c3039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_games\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 95\u001b[0m, in \u001b[0;36mDQNAgent.evaluate\u001b[1;34m(self, agent, n_games, t_max, render, verbose)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done \u001b[38;5;129;01mand\u001b[39;00m steps \u001b[38;5;241m<\u001b[39m t_max: \n\u001b[0;32m     93\u001b[0m     \u001b[38;5;66;03m# Get next action \u001b[39;00m\n\u001b[0;32m     94\u001b[0m     next_action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(agent\u001b[38;5;241m.\u001b[39mget_qs(current_state))\n\u001b[1;32m---> 95\u001b[0m     current_state, reward, done, truncated \u001b[38;5;241m=\u001b[39m \u001b[43mttc_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     done \u001b[38;5;241m=\u001b[39m done \u001b[38;5;241m|\u001b[39m truncated\n\u001b[0;32m     97\u001b[0m     cum_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "Cell \u001b[1;32mIn[11], line 34\u001b[0m, in \u001b[0;36mTimeToCollision.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m---> 34\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_obs, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_state(), reward, done, truncated\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:51\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\highway_env\\envs\\common\\abstract.py:235\u001b[0m, in \u001b[0;36mAbstractEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe road and vehicle must be initialized in the environment implementation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy_frequency\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 235\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_simulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    237\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_type\u001b[38;5;241m.\u001b[39mobserve()\n\u001b[0;32m    238\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reward(action)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\highway_env\\envs\\common\\abstract.py:257\u001b[0m, in \u001b[0;36mAbstractEnv._simulate\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \\\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanual_control\u001b[39m\u001b[38;5;124m\"\u001b[39m] \\\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimulation_frequency\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy_frequency\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_type\u001b[38;5;241m.\u001b[39mact(action)\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroad\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimulation_frequency\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\highway_env\\road\\road.py:324\u001b[0m, in \u001b[0;36mRoad.act\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decide the actions of each entity on the road.\"\"\"\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vehicle \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvehicles:\n\u001b[1;32m--> 324\u001b[0m     \u001b[43mvehicle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\highway_env\\vehicle\\behavior.py:100\u001b[0m, in \u001b[0;36mIDMVehicle.act\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     97\u001b[0m action[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msteering\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(action[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msteering\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMAX_STEERING_ANGLE, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMAX_STEERING_ANGLE)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Longitudinal: IDM\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m front_vehicle, rear_vehicle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneighbour_vehicles\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlane_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m action[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macceleration\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macceleration(ego_vehicle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    102\u001b[0m                                            front_vehicle\u001b[38;5;241m=\u001b[39mfront_vehicle,\n\u001b[0;32m    103\u001b[0m                                            rear_vehicle\u001b[38;5;241m=\u001b[39mrear_vehicle)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# When changing lane, check both current and target lanes\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\highway_env\\road\\road.py:361\u001b[0m, in \u001b[0;36mRoad.neighbour_vehicles\u001b[1;34m(self, vehicle, lane_index)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvehicles \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjects:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vehicle \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, Landmark):  \u001b[38;5;66;03m# self.network.is_connected_road(v.lane_index,\u001b[39;00m\n\u001b[0;32m    360\u001b[0m         \u001b[38;5;66;03m# lane_index, same_lane=True):\u001b[39;00m\n\u001b[1;32m--> 361\u001b[0m         s_v, lat_v \u001b[38;5;241m=\u001b[39m \u001b[43mlane\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_coordinates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lane\u001b[38;5;241m.\u001b[39mon_lane(v\u001b[38;5;241m.\u001b[39mposition, s_v, lat_v, margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    363\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\highway_env\\road\\lane.py:190\u001b[0m, in \u001b[0;36mStraightLane.local_coordinates\u001b[1;34m(self, position)\u001b[0m\n\u001b[0;32m    188\u001b[0m delta \u001b[38;5;241m=\u001b[39m position \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart\n\u001b[0;32m    189\u001b[0m longitudinal \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(delta, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirection)\n\u001b[1;32m--> 190\u001b[0m lateral \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdirection_lateral\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(longitudinal), \u001b[38;5;28mfloat\u001b[39m(lateral)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.evaluate(agent, n_games=3, t_max=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
