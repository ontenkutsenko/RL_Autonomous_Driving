{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVS1JrCRGQZ1",
        "outputId": "d1737503-a7cb-49da-d4c1-91c95fb041f7"
      },
      "outputs": [],
      "source": [
        "!pip install gymnasium highway-env stable-baselines3[extra]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OebvqYsR91Pt",
        "outputId": "ee60ca38-88e9-48cf-b76b-badf2c0c5f9a"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "# import highway_env\n",
        "# highway_env.register_highway_envs()\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import deque\n",
        "from tqdm.notebook import tqdm\n",
        "import itertools\n",
        "import pickle\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Activation, Flatten\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.optimizers import Adam\n",
        "from scipy.signal import convolve, gaussian\n",
        "import tensorflow as tf\n",
        "\n",
        "random.seed(1)\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def timeit(f):\n",
        "\n",
        "    def timed(*args, **kw):\n",
        "\n",
        "        ts = time.time()\n",
        "        result = f(*args, **kw)\n",
        "        te = time.time()\n",
        "\n",
        "        print('func:%r took: %2.4f sec' % \\\n",
        "          (f.__name__, te-ts))\n",
        "        return result\n",
        "\n",
        "    return timed\n",
        "\n",
        "action_names = ['left', 'idle', 'right', 'faster', 'slower']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gdrhVZwR-Uxz"
      },
      "outputs": [],
      "source": [
        "default_config = {\n",
        "    \"lanes_count\" : 4,\n",
        "    \"vehicles_count\": 50,\n",
        "    \"duration\": 40,\n",
        "    \"other_vehicles_type\": \"highway_env.vehicle.behavior.IDMVehicle\",\n",
        "    \"initial_spacing\": 2,\n",
        "    \"simulation_frequency\": 15,\n",
        "    \"policy_frequency\": 5,\n",
        "    \"collision_reward\": -200,\n",
        "    \"right_lane_reward\": 10,\n",
        "    \"high_speed_reward\": 20,\n",
        "    \"lane_change_reward\": 2,\n",
        "    \"reward_speed_range\": [20, 30],\n",
        "    \"normalize_reward\": False,\n",
        "    \"screen_width\": 800,\n",
        "    \"screen_height\": 600,\n",
        "    \"centering_position\": [0.5, 0.5],\n",
        "    \"scaling\": 5,\n",
        "    \"show_trajectories\": True,\n",
        "    \"render_agent\": True,\n",
        "    \"offscreen_rendering\": False\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RHFonput-VTx"
      },
      "outputs": [],
      "source": [
        "class TimeToCollision:\n",
        "    def __init__(self, \n",
        "                horizon=5,\n",
        "                policy_frequency=5,\n",
        "                simulation_frequency=15,\n",
        "                high_speed_reward=10,\n",
        "                right_lane_reward=10,\n",
        "                lane_change_reward=-1,\n",
        "                render_mode=None):\n",
        "\n",
        "        self.config = default_config.copy()\n",
        "        self.config[\"observation\"] =  {\n",
        "                \"type\": \"TimeToCollision\",\n",
        "                \"horizon\": horizon}\n",
        "        self.horizon = horizon\n",
        "\n",
        "        self.config.update({\n",
        "            \"policy_frequency\": policy_frequency,\n",
        "            \"simulation_frequency\": simulation_frequency,\n",
        "            \"high_speed_reward\": high_speed_reward,\n",
        "            \"right_lane_reward\": right_lane_reward,\n",
        "            \"lane_change_reward\": lane_change_reward\n",
        "        })\n",
        "\n",
        "        with gym.make(\"highway-fast-v0\", config=self.config, render_mode=render_mode) as env:\n",
        "            self.env = env\n",
        "            self.obs_space_shape = env.observation_space.shape\n",
        "            self.action_space_size = env.action_space.n\n",
        "\n",
        "    def get_state(self):\n",
        "        grid = self.env.get_wrapper_attr('vehicle').speed_index\n",
        "        # return self.current_obs[grid]\n",
        "        return self.current_obs\n",
        "\n",
        "    def reset(self, seed='random'):\n",
        "        if seed == 'random':\n",
        "            seed = np.random.randint(100000)\n",
        "        self.current_obs, info = self.env.reset(seed=seed)\n",
        "        return self.get_state()\n",
        "\n",
        "    def step(self, action):\n",
        "        self.current_obs, reward, done, truncated, info = self.env.step(action)\n",
        "        return self.get_state(), reward, done, truncated\n",
        "\n",
        "    def close(self):\n",
        "        self.env.close()\n",
        "\n",
        "    def action_space_sample(self):\n",
        "        return self.env.action_space.sample()\n",
        "\n",
        "    def test_env(self, sleep_time=1):\n",
        "        with gym.make(\"highway-v0\", config=self.config, render_mode='human') as env:\n",
        "            self.env = env\n",
        "            obs = env.reset()\n",
        "            for _ in range(1000):\n",
        "                action = env.action_space.sample()\n",
        "                self.current_obs, reward, done, truncated, info = env.step(action)\n",
        "                print(self.get_state(env), reward)\n",
        "                if done:\n",
        "                    break\n",
        "                time.sleep(sleep_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TimeToCollisionVec:\n",
        "    def __init__(self, \n",
        "                num_envs=1, \n",
        "                horizon=5,\n",
        "                policy_frequency=5,\n",
        "                simulation_frequency=15,\n",
        "                high_speed_reward=10,\n",
        "                right_lane_reward=10,\n",
        "                lane_change_reward=-1,\n",
        "                obs_type='speed-restricted',\n",
        "                ):\n",
        "        \"\"\"\n",
        "        Constructor for the TimeToCollisionVec class.\n",
        "        Args:\n",
        "            num_envs: Number of parallel environments to run.\n",
        "            horizon: The number of timesteps to look ahead for the TimeToCollision observation.\n",
        "            policy_frequency: The frequency at which the policy is evaluated.\n",
        "            simulation_frequency: The frequency at which the simulation is run.\n",
        "            high_speed_reward: The reward given for driving at high speed.\n",
        "            right_lane_reward: The reward given for driving in the right lane.\n",
        "            lane_change_reward: The reward given for changing lanes.\n",
        "            obs_type: The type of observation to use. Choose from 'normal' or 'speed-restricted'\n",
        "                'normal': The normal TimeToCollision observation (x3 different speeds the car could be at)\n",
        "                'speed-restricted': Only one of the TimeToCollision observations is used (the speed the car is currently at) (less complex observation space)\n",
        "        \"\"\"\n",
        "        \n",
        "        self.config = default_config.copy()\n",
        "        self.config[\"observation\"] =  {\n",
        "                \"type\": \"TimeToCollision\",\n",
        "                \"horizon\": horizon}\n",
        "        self.horizon = horizon\n",
        "\n",
        "        self.config.update({\n",
        "            \"policy_frequency\": policy_frequency,\n",
        "            \"simulation_frequency\": simulation_frequency,\n",
        "            \"high_speed_reward\": high_speed_reward,\n",
        "            \"right_lane_reward\": right_lane_reward,\n",
        "            \"lane_change_reward\": lane_change_reward\n",
        "        })\n",
        "        \n",
        "        self.num_envs = num_envs\n",
        "        self.obs_type = obs_type\n",
        "\n",
        "        with gym.make(\"highway-fast-v0\", config=self.config) as env:\n",
        "            self.env = gym.vector.AsyncVectorEnv([lambda: env for _ in range(num_envs)])\n",
        "            self.obs_space_shape = env.observation_space.shape if obs_type == 'normal' else env.observation_space.shape[1:]\n",
        "            self.action_space_size = env.action_space.n\n",
        "\n",
        "    def get_speeds(self):\n",
        "        return [car.speed_index for car in self.env.get_attr('vehicle')]\n",
        "    \n",
        "    def get_state(self, obs):\n",
        "        if self.obs_type == 'normal':\n",
        "            return obs\n",
        "        else:\n",
        "            speed_indices = self.get_speeds()\n",
        "            return np.array([obs[i][speed_indices[i]] for i in range(self.num_envs)])\n",
        "    \n",
        "    def reset(self, seeds=None):\n",
        "        if seeds is None:\n",
        "            seeds = [np.random.randint(100000) for _ in range(self.num_envs)]\n",
        "        obs, info = self.env.reset(seed=seeds)\n",
        "        return self.get_state(obs)\n",
        "    \n",
        "    def step(self, actions):\n",
        "        obs, rewards, dones, truncates, info = self.env.step(actions)\n",
        "        return self.get_state(obs), np.array(rewards), np.array(dones), np.array(truncates)\n",
        "    \n",
        "    def close(self):\n",
        "        self.env.close()    \n",
        "\n",
        "    def action_space_sample(self):  \n",
        "        return self.env.action_space.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def CNN(obs_space_shape, action_space_size):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, (2, 2), input_shape=obs_space_shape))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(64))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(action_space_size, activation='linear'))\n",
        "    model.compile(loss='mse', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def NN(obs_space_shape, action_space_size):\n",
        "    # Make the multiplication in the obs space shape tuple \n",
        "    obs_size = (np.prod(obs_space_shape),)\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_shape=obs_size, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(action_space_size, activation='linear'))\n",
        "    model.compile(loss='mse', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "z-XmWnhw-w9A"
      },
      "outputs": [],
      "source": [
        "class DQNAgent:\n",
        "    def __init__(self, \n",
        "                 env,\n",
        "                 model_type='CNN'):\n",
        "        assert not (model_type == 'CNN' and env.obs_type == 'speed-restricted'), 'CNN model cannot be used with speed-restricted observation type'\n",
        "        self.env = env\n",
        "        self.model_type = model_type\n",
        "\n",
        "        # Main model - what gets trained every step\n",
        "        self.model = self.create_model()\n",
        "\n",
        "        # Target model - what we predict every step\n",
        "        self.target_model = self.create_model()\n",
        "        self.target_model.set_weights(self.model.get_weights())\n",
        "        self.target_update_counter = 0\n",
        "\n",
        "    def create_model(self):\n",
        "        if self.model_type == 'CNN':\n",
        "            return CNN(self.env.obs_space_shape, self.env.action_space_size)\n",
        "        elif self.model_type == 'NN':\n",
        "            return NN(self.env.obs_space_shape, self.env.action_space_size)\n",
        "        \n",
        "    def init(self, epsilon=1,\n",
        "             min_eps=0.001,\n",
        "             eps_decay=0.998,\n",
        "             gamma=0.99,\n",
        "             replay_memory=50_000,\n",
        "             batch_size=64,\n",
        "             update_weights_freq=5,\n",
        "             min_replay_memory=1_000\n",
        "             ):\n",
        "        self.initialized = True\n",
        "        self.epsilon, self.min_eps, self.eps_decay = epsilon, min_eps, eps_decay\n",
        "        self.replay_memory = deque(maxlen=replay_memory)\n",
        "        self.update_weights_freq = update_weights_freq\n",
        "        self.min_replay_memory = min_replay_memory\n",
        "        self.batch_size = batch_size\n",
        "        self.gamma = gamma\n",
        "        self.current_episode, self.step = 0, 0\n",
        "        self.mean_rw_history, self.mean_steps_history, self.loss_hist, self.action_distribution_history = [], [], [], []\n",
        "\n",
        "    def update_replay_memory(self, transition):\n",
        "        self.replay_memory.extend(transition)\n",
        "\n",
        "    def reshape_states(self, state):\n",
        "        if self.model_type == 'CNN':\n",
        "            return state\n",
        "        elif self.model_type == 'NN':\n",
        "            return state.reshape(-1, np.prod(state.shape[1:]))\n",
        "\n",
        "    def get_qs(self, state):\n",
        "        state_ = self.reshape_states(state)\n",
        "        return self.model.predict(state_, verbose=0)\n",
        "\n",
        "    @timeit\n",
        "    def train_model(self, terminal_state):\n",
        "        if len(self.replay_memory) < self.min_replay_memory:\n",
        "            return\n",
        "\n",
        "        minibatch = random.sample(self.replay_memory, self.batch_size)\n",
        "\n",
        "        current_states = np.array([transition[0] for transition in minibatch])\n",
        "        current_states_  = self.reshape_states(current_states)\n",
        "        current_qs_list = self.model.predict(current_states_, verbose=0)                     # The model that gets trained every step\n",
        "\n",
        "        new_current_states = np.array([transition[3] for transition in minibatch])\n",
        "        new_current_states_ = self.reshape_states(new_current_states)\n",
        "        future_qs_list = self.target_model.predict(new_current_states_, verbose=0)             # The model that doesn't get trained every step\n",
        "\n",
        "        X,y = [], []\n",
        "\n",
        "        for index, (current_state, action, reward, new_current_state, done) in enumerate(minibatch):\n",
        "            new_q = reward\n",
        "\n",
        "            if not done:\n",
        "                # In case of a non-terminal state, add future reward\n",
        "                max_future_q = np.max(future_qs_list[index])\n",
        "                new_q += self.gamma * max_future_q\n",
        "\n",
        "            current_qs = current_qs_list[index]\n",
        "            # Update the q value for the action taken\n",
        "            current_qs[action] = new_q\n",
        "\n",
        "            X.append(self.reshape_states(current_state))\n",
        "            y.append(current_qs)\n",
        "\n",
        "        history = self.model.fit(np.array(X), np.array(y), batch_size=self.batch_size, verbose=0, shuffle=False)\n",
        "\n",
        "        if terminal_state:\n",
        "            self.target_update_counter += 1\n",
        "        # If counter reaches set value, update target network with weights of main network\n",
        "        if self.target_update_counter > self.update_weights_freq:\n",
        "            self.target_model.set_weights(self.model.get_weights())\n",
        "            self.target_update_counter = 0\n",
        "\n",
        "        return history.history['loss'][0] \n",
        "\n",
        "    def epsilon_greedy(self,current_state):\n",
        "        if np.random.random() > self.epsilon:\n",
        "            action = np.argmax(self.get_qs(current_state), axis=1)\n",
        "        else:\n",
        "            # Generate self.env.num_envs random actions\n",
        "            action = self.env.action_space_sample()\n",
        "        return np.array(action)\n",
        "\n",
        "    def decay_eps(self):\n",
        "        if self.epsilon > self.min_eps:\n",
        "            self.epsilon *= self.eps_decay\n",
        "            self.epsilon = max(self.min_eps, self.epsilon)\n",
        "\n",
        "\n",
        "    def train(self, episodes=10_000, episode_duration=200, evaluation_freq=25):\n",
        "        if not self.initialized:\n",
        "          print('Warning! Initializing with default parameters')\n",
        "          self.init()\n",
        "\n",
        "        start_time = time.time()\n",
        "        for episode in tqdm(range(self.current_episode, episodes), unit='episode'):\n",
        "            current_states = self.env.reset()\n",
        "            self.current_episode += 1\n",
        "            \n",
        "            count = 0\n",
        "            # Episode cycle\n",
        "            while count < episode_duration:\n",
        "                action = self.epsilon_greedy(current_states)\n",
        "                new_states, rewards, done, truncate = self.env.step(action)\n",
        "                done = done | truncate\n",
        "                \n",
        "                to_append = list(zip(current_states, action, rewards, new_states, done))\n",
        "                self.update_replay_memory(to_append)\n",
        "                # self.loss_hist.append(self.train_model(False))\n",
        "\n",
        "                current_states = new_states\n",
        "                self.step += 1\n",
        "                count += 1\n",
        "\n",
        "            loss = self.train_model(True)\n",
        "            self.loss_hist.append(loss) if loss is not None else None\n",
        "\n",
        "            if self.current_episode % evaluation_freq == 0:\n",
        "                rewards_mean, steps_mean, action_distribution = self.evaluate_and_render(n_games=3, steps=200)\n",
        "                self.mean_rw_history.append(rewards_mean)\n",
        "                self.mean_steps_history.append(steps_mean)\n",
        "                self.action_distribution_history.append(action_distribution)\n",
        "\n",
        "                clear_output(wait=True)\n",
        "\n",
        "                print(f\"episode = {self.current_episode}, epsilon = {self.epsilon}, mean reward = {rewards_mean}, mean steps = {steps_mean}\")\n",
        "                print(f\"total steps = {self.step*self.env.num_envs}, time_elapsed = {time.time() - start_time}, fps = {self.step*self.env.num_envs / (time.time() - start_time)}\")\n",
        "                \n",
        "                plt.figure(figsize=[16, 10])\n",
        "                plt.suptitle(f\"Stats for episode {self.current_episode}\")\n",
        "                plt.subplot(2, 2, 1)\n",
        "                plt.title(\"Mean reward per episode\")\n",
        "                plt.plot(self.mean_rw_history)\n",
        "                plt.grid()\n",
        "\n",
        "                plt.subplot(2, 2, 2)\n",
        "                plt.title(\"Mean steps per episode\")\n",
        "                plt.plot(self.mean_steps_history)\n",
        "                plt.grid()\n",
        "\n",
        "                plt.subplot(2, 2, 3)\n",
        "                plt.title(\"Action distribution for the current episode\")\n",
        "                plt.bar(action_names, action_distribution)\n",
        "                plt.grid()\n",
        "\n",
        "                plt.subplot(2, 2, 4)\n",
        "                plt.title(\"Action distribution history for all episodes\")\n",
        "                action_distribution_history = np.array(self.action_distribution_history)\n",
        "                for i in range(self.env.action_space_size):\n",
        "                    plt.plot(action_distribution_history[:, i], label=f'{action_names[i]}')\n",
        "                plt.legend()\n",
        "                plt.grid()\n",
        "                \n",
        "                plt.show()\n",
        "\n",
        "            self.decay_eps()\n",
        "\n",
        "    def evaluate(self, agent, n_games=3, steps=200, verbose=True):\n",
        "        sim_freq, pol_freq, horizon = self.env.config['simulation_frequency'], self.env.config['policy_frequency'], self.env.horizon\n",
        "        ttc_vec_env = TimeToCollisionVec(num_envs=n_games, horizon=horizon, policy_frequency=pol_freq, simulation_frequency=sim_freq, render_mode=None)\n",
        "\n",
        "        print('Evaluating...') if verbose else None\n",
        "        total_reward, finished_games = 0, 0\n",
        "        obs = ttc_vec_env.reset()\n",
        "        actions_hist = []\n",
        "        for _ in range(steps):\n",
        "            actions = np.argmax(agent.get_qs(obs), axis=1)\n",
        "            actions_hist.extend(actions)\n",
        "            obs, rewards_, dones, _ = ttc_vec_env.step(actions)\n",
        "            print(actions, rewards_)\n",
        "            total_reward += rewards_.sum()\n",
        "            finished_games += dones.sum()\n",
        "\n",
        "        total_steps = steps * n_games\n",
        "        average_reward = total_reward / finished_games if finished_games > 0 else 0\n",
        "        average_steps = total_steps / finished_games if finished_games > 0 else steps\n",
        "        # Calculate the action distribution\n",
        "        actions_hist = np.array(actions_hist)\n",
        "        action_distribution = np.array([np.sum(actions_hist == i) for i in range(ttc_vec_env.action_space_size)]) / len(actions_hist)\n",
        "        ttc_vec_env.close()        \n",
        "        return average_reward, average_steps, action_distribution\n",
        "\n",
        "\n",
        "    def evaluate_and_render(self, n_games=3, steps=300, verbose=True):\n",
        "        sim_freq, pol_freq, horizon = self.env.config['simulation_frequency'], self.env.config['policy_frequency'], self.env.horizon\n",
        "        ttc_env = TimeToCollision(policy_frequency=pol_freq, simulation_frequency=sim_freq, horizon=horizon, render_mode='human')\n",
        "\n",
        "        print('Evaluating...') if verbose else None\n",
        "        rewards, steps_array, actions_hist = [], [], []\n",
        "        for i in tqdm(range(n_games)):\n",
        "            cum_reward = 0\n",
        "            step, done = 0, False\n",
        "            current_state = ttc_env.reset(seed=np.random.randint(100000+i))\n",
        "            while not done and step < steps:\n",
        "                # Get next action\n",
        "                next_action = np.argmax(self.get_qs(current_state.reshape(1, *current_state.shape)))\n",
        "                actions_hist.append(next_action)\n",
        "                current_state, reward, done, truncated = ttc_env.step(next_action)\n",
        "                done = done | truncated\n",
        "                cum_reward += reward\n",
        "                step += 1\n",
        "            rewards.append(cum_reward)\n",
        "            steps_array.append(step)\n",
        "        actions_hist = np.array(actions_hist)\n",
        "        action_distribution = np.array([np.sum(actions_hist == i) for i in range(ttc_env.action_space_size)]) / len(actions_hist)\n",
        "\n",
        "        ttc_env.close()\n",
        "        return np.mean(rewards), np.mean(steps_array), action_distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f276848b22ce4daea2979eb23153742b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?episode/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "func:'train_model' took: 0.0000 sec\n"
          ]
        }
      ],
      "source": [
        "ttc_vec = TimeToCollisionVec(num_envs=10, \n",
        "                             horizon=5, \n",
        "                             policy_frequency=4, \n",
        "                             simulation_frequency=20,\n",
        "                             obs_type='speed-restricted',\n",
        ")\n",
        "agent = DQNAgent(ttc_vec, model_type='NN')\n",
        "agent.init(\n",
        "    epsilon=1,\n",
        "    min_eps=0.01,\n",
        "    eps_decay=0.992,  #.998\n",
        "    gamma=0.99,\n",
        "    replay_memory=10_000,  #50_000\n",
        "    batch_size=64,   # 64\n",
        "    update_weights_freq=10,  #5\n",
        "    min_replay_memory=1_000,\n",
        ")\n",
        "\n",
        "agent.train(episodes=200,\n",
        "            episode_duration=50,\n",
        "            evaluation_freq=15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "________________________________________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8BhZl5k4MNb4",
        "outputId": "25f13f03-5873-45e3-ca66-583d171b2920"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.configure to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.configure` for environment variables or `env.get_wrapper_attr('configure')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 99.5     |\n",
            "|    ep_rew_mean      | 80.7     |\n",
            "|    exploration_rate | 0.961    |\n",
            "| time/               |          |\n",
            "|    episodes         | 4        |\n",
            "|    fps              | 79       |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 398      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 94.4     |\n",
            "|    ep_rew_mean      | 76       |\n",
            "|    exploration_rate | 0.926    |\n",
            "| time/               |          |\n",
            "|    episodes         | 8        |\n",
            "|    fps              | 90       |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 755      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 92.2     |\n",
            "|    ep_rew_mean      | 75.5     |\n",
            "|    exploration_rate | 0.892    |\n",
            "| time/               |          |\n",
            "|    episodes         | 12       |\n",
            "|    fps              | 88       |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 1106     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.184    |\n",
            "|    n_updates        | 26       |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 102      |\n",
            "|    ep_rew_mean      | 84.5     |\n",
            "|    exploration_rate | 0.839    |\n",
            "| time/               |          |\n",
            "|    episodes         | 16       |\n",
            "|    fps              | 85       |\n",
            "|    time_elapsed     | 19       |\n",
            "|    total_timesteps  | 1640     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.00841  |\n",
            "|    n_updates        | 159      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 94.2     |\n",
            "|    ep_rew_mean      | 78.2     |\n",
            "|    exploration_rate | 0.815    |\n",
            "| time/               |          |\n",
            "|    episodes         | 20       |\n",
            "|    fps              | 87       |\n",
            "|    time_elapsed     | 21       |\n",
            "|    total_timesteps  | 1884     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0143   |\n",
            "|    n_updates        | 220      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 93       |\n",
            "|    ep_rew_mean      | 78.1     |\n",
            "|    exploration_rate | 0.781    |\n",
            "| time/               |          |\n",
            "|    episodes         | 24       |\n",
            "|    fps              | 88       |\n",
            "|    time_elapsed     | 25       |\n",
            "|    total_timesteps  | 2233     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0607   |\n",
            "|    n_updates        | 308      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 87.8     |\n",
            "|    ep_rew_mean      | 73.9     |\n",
            "|    exploration_rate | 0.759    |\n",
            "| time/               |          |\n",
            "|    episodes         | 28       |\n",
            "|    fps              | 89       |\n",
            "|    time_elapsed     | 27       |\n",
            "|    total_timesteps  | 2457     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0122   |\n",
            "|    n_updates        | 364      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 92.9     |\n",
            "|    ep_rew_mean      | 79       |\n",
            "|    exploration_rate | 0.709    |\n",
            "| time/               |          |\n",
            "|    episodes         | 32       |\n",
            "|    fps              | 87       |\n",
            "|    time_elapsed     | 34       |\n",
            "|    total_timesteps  | 2973     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.00532  |\n",
            "|    n_updates        | 493      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 94.1     |\n",
            "|    ep_rew_mean      | 80.1     |\n",
            "|    exploration_rate | 0.668    |\n",
            "| time/               |          |\n",
            "|    episodes         | 36       |\n",
            "|    fps              | 88       |\n",
            "|    time_elapsed     | 38       |\n",
            "|    total_timesteps  | 3388     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0378   |\n",
            "|    n_updates        | 596      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 95.7     |\n",
            "|    ep_rew_mean      | 81.5     |\n",
            "|    exploration_rate | 0.625    |\n",
            "| time/               |          |\n",
            "|    episodes         | 40       |\n",
            "|    fps              | 86       |\n",
            "|    time_elapsed     | 44       |\n",
            "|    total_timesteps  | 3826     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0639   |\n",
            "|    n_updates        | 706      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 92.6     |\n",
            "|    ep_rew_mean      | 79       |\n",
            "|    exploration_rate | 0.601    |\n",
            "| time/               |          |\n",
            "|    episodes         | 44       |\n",
            "|    fps              | 86       |\n",
            "|    time_elapsed     | 46       |\n",
            "|    total_timesteps  | 4075     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.07     |\n",
            "|    n_updates        | 768      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 88.8     |\n",
            "|    ep_rew_mean      | 75.8     |\n",
            "|    exploration_rate | 0.582    |\n",
            "| time/               |          |\n",
            "|    episodes         | 48       |\n",
            "|    fps              | 87       |\n",
            "|    time_elapsed     | 48       |\n",
            "|    total_timesteps  | 4261     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.144    |\n",
            "|    n_updates        | 815      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 90       |\n",
            "|    ep_rew_mean      | 77.2     |\n",
            "|    exploration_rate | 0.542    |\n",
            "| time/               |          |\n",
            "|    episodes         | 52       |\n",
            "|    fps              | 87       |\n",
            "|    time_elapsed     | 53       |\n",
            "|    total_timesteps  | 4678     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0188   |\n",
            "|    n_updates        | 919      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 88.7     |\n",
            "|    ep_rew_mean      | 76.3     |\n",
            "|    exploration_rate | 0.513    |\n",
            "| time/               |          |\n",
            "|    episodes         | 56       |\n",
            "|    fps              | 85       |\n",
            "|    time_elapsed     | 57       |\n",
            "|    total_timesteps  | 4967     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0296   |\n",
            "|    n_updates        | 991      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 86       |\n",
            "|    ep_rew_mean      | 74       |\n",
            "|    exploration_rate | 0.494    |\n",
            "| time/               |          |\n",
            "|    episodes         | 60       |\n",
            "|    fps              | 85       |\n",
            "|    time_elapsed     | 60       |\n",
            "|    total_timesteps  | 5162     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0491   |\n",
            "|    n_updates        | 1040     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 84.5     |\n",
            "|    ep_rew_mean      | 72.8     |\n",
            "|    exploration_rate | 0.47     |\n",
            "| time/               |          |\n",
            "|    episodes         | 64       |\n",
            "|    fps              | 86       |\n",
            "|    time_elapsed     | 62       |\n",
            "|    total_timesteps  | 5406     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0297   |\n",
            "|    n_updates        | 1101     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 87       |\n",
            "|    ep_rew_mean      | 75.2     |\n",
            "|    exploration_rate | 0.42     |\n",
            "| time/               |          |\n",
            "|    episodes         | 68       |\n",
            "|    fps              | 85       |\n",
            "|    time_elapsed     | 68       |\n",
            "|    total_timesteps  | 5915     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0818   |\n",
            "|    n_updates        | 1228     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 86.2     |\n",
            "|    ep_rew_mean      | 74.7     |\n",
            "|    exploration_rate | 0.392    |\n",
            "| time/               |          |\n",
            "|    episodes         | 72       |\n",
            "|    fps              | 85       |\n",
            "|    time_elapsed     | 72       |\n",
            "|    total_timesteps  | 6205     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0533   |\n",
            "|    n_updates        | 1301     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 87       |\n",
            "|    ep_rew_mean      | 75.2     |\n",
            "|    exploration_rate | 0.352    |\n",
            "| time/               |          |\n",
            "|    episodes         | 76       |\n",
            "|    fps              | 86       |\n",
            "|    time_elapsed     | 76       |\n",
            "|    total_timesteps  | 6609     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.108    |\n",
            "|    n_updates        | 1402     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 86.1     |\n",
            "|    ep_rew_mean      | 74.6     |\n",
            "|    exploration_rate | 0.325    |\n",
            "| time/               |          |\n",
            "|    episodes         | 80       |\n",
            "|    fps              | 86       |\n",
            "|    time_elapsed     | 79       |\n",
            "|    total_timesteps  | 6888     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0153   |\n",
            "|    n_updates        | 1471     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 85.6     |\n",
            "|    ep_rew_mean      | 74.2     |\n",
            "|    exploration_rate | 0.296    |\n",
            "| time/               |          |\n",
            "|    episodes         | 84       |\n",
            "|    fps              | 85       |\n",
            "|    time_elapsed     | 83       |\n",
            "|    total_timesteps  | 7187     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.247    |\n",
            "|    n_updates        | 1546     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 84.1     |\n",
            "|    ep_rew_mean      | 72.9     |\n",
            "|    exploration_rate | 0.274    |\n",
            "| time/               |          |\n",
            "|    episodes         | 88       |\n",
            "|    fps              | 85       |\n",
            "|    time_elapsed     | 86       |\n",
            "|    total_timesteps  | 7404     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.285    |\n",
            "|    n_updates        | 1600     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 83.9     |\n",
            "|    ep_rew_mean      | 72.9     |\n",
            "|    exploration_rate | 0.243    |\n",
            "| time/               |          |\n",
            "|    episodes         | 92       |\n",
            "|    fps              | 84       |\n",
            "|    time_elapsed     | 91       |\n",
            "|    total_timesteps  | 7721     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.169    |\n",
            "|    n_updates        | 1680     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 83.3     |\n",
            "|    ep_rew_mean      | 72.4     |\n",
            "|    exploration_rate | 0.216    |\n",
            "| time/               |          |\n",
            "|    episodes         | 96       |\n",
            "|    fps              | 83       |\n",
            "|    time_elapsed     | 95       |\n",
            "|    total_timesteps  | 7995     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0496   |\n",
            "|    n_updates        | 1748     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 84.5     |\n",
            "|    ep_rew_mean      | 73.4     |\n",
            "|    exploration_rate | 0.172    |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 102      |\n",
            "|    total_timesteps  | 8448     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.228    |\n",
            "|    n_updates        | 1861     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 87       |\n",
            "|    ep_rew_mean      | 76.2     |\n",
            "|    exploration_rate | 0.108    |\n",
            "| time/               |          |\n",
            "|    episodes         | 104      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 111      |\n",
            "|    total_timesteps  | 9097     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.288    |\n",
            "|    n_updates        | 2024     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 86       |\n",
            "|    ep_rew_mean      | 75.6     |\n",
            "|    exploration_rate | 0.0837   |\n",
            "| time/               |          |\n",
            "|    episodes         | 108      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 113      |\n",
            "|    total_timesteps  | 9350     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0686   |\n",
            "|    n_updates        | 2087     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 86       |\n",
            "|    ep_rew_mean      | 75.9     |\n",
            "|    exploration_rate | 0.0487   |\n",
            "| time/               |          |\n",
            "|    episodes         | 112      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 117      |\n",
            "|    total_timesteps  | 9707     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0621   |\n",
            "|    n_updates        | 2176     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 84.6     |\n",
            "|    ep_rew_mean      | 74.8     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 116      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 123      |\n",
            "|    total_timesteps  | 10096    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.105    |\n",
            "|    n_updates        | 2273     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 85.4     |\n",
            "|    ep_rew_mean      | 75.8     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 120      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 127      |\n",
            "|    total_timesteps  | 10428    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0548   |\n",
            "|    n_updates        | 2356     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 84.5     |\n",
            "|    ep_rew_mean      | 75.1     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 124      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 129      |\n",
            "|    total_timesteps  | 10681    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0523   |\n",
            "|    n_updates        | 2420     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 85.1     |\n",
            "|    ep_rew_mean      | 75.7     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 128      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 133      |\n",
            "|    total_timesteps  | 10967    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0677   |\n",
            "|    n_updates        | 2491     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 87.4     |\n",
            "|    ep_rew_mean      | 78.1     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 132      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 142      |\n",
            "|    total_timesteps  | 11713    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.283    |\n",
            "|    n_updates        | 2678     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 88.9     |\n",
            "|    ep_rew_mean      | 79.9     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 136      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 149      |\n",
            "|    total_timesteps  | 12276    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.108    |\n",
            "|    n_updates        | 2818     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 87.7     |\n",
            "|    ep_rew_mean      | 79.1     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 140      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 153      |\n",
            "|    total_timesteps  | 12592    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0567   |\n",
            "|    n_updates        | 2897     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 90.4     |\n",
            "|    ep_rew_mean      | 81.6     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 144      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 159      |\n",
            "|    total_timesteps  | 13116    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0891   |\n",
            "|    n_updates        | 3028     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 93.1     |\n",
            "|    ep_rew_mean      | 84.2     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 148      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 165      |\n",
            "|    total_timesteps  | 13573    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.178    |\n",
            "|    n_updates        | 3143     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 97       |\n",
            "|    ep_rew_mean      | 88       |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 152      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 175      |\n",
            "|    total_timesteps  | 14380    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.161    |\n",
            "|    n_updates        | 3344     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 103      |\n",
            "|    ep_rew_mean      | 93.3     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 156      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 184      |\n",
            "|    total_timesteps  | 15258    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0906   |\n",
            "|    n_updates        | 3564     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 103      |\n",
            "|    ep_rew_mean      | 93.6     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 160      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 188      |\n",
            "|    total_timesteps  | 15500    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.16     |\n",
            "|    n_updates        | 3624     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 105      |\n",
            "|    ep_rew_mean      | 94.9     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 164      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 192      |\n",
            "|    total_timesteps  | 15872    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.116    |\n",
            "|    n_updates        | 3717     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 105      |\n",
            "|    ep_rew_mean      | 95.1     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 168      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 198      |\n",
            "|    total_timesteps  | 16388    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0839   |\n",
            "|    n_updates        | 3846     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 104      |\n",
            "|    ep_rew_mean      | 94.2     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 172      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 201      |\n",
            "|    total_timesteps  | 16571    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.156    |\n",
            "|    n_updates        | 3892     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 101      |\n",
            "|    ep_rew_mean      | 92.6     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 176      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 203      |\n",
            "|    total_timesteps  | 16758    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.466    |\n",
            "|    n_updates        | 3939     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 103      |\n",
            "|    ep_rew_mean      | 93.5     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 180      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 208      |\n",
            "|    total_timesteps  | 17147    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.228    |\n",
            "|    n_updates        | 4036     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 105      |\n",
            "|    ep_rew_mean      | 95.6     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 184      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 215      |\n",
            "|    total_timesteps  | 17659    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.16     |\n",
            "|    n_updates        | 4164     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 107      |\n",
            "|    ep_rew_mean      | 97.7     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 188      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 219      |\n",
            "|    total_timesteps  | 18078    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.406    |\n",
            "|    n_updates        | 4269     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 108      |\n",
            "|    ep_rew_mean      | 98.9     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 192      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 224      |\n",
            "|    total_timesteps  | 18521    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.113    |\n",
            "|    n_updates        | 4380     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 108      |\n",
            "|    ep_rew_mean      | 99.3     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 196      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 229      |\n",
            "|    total_timesteps  | 18838    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.106    |\n",
            "|    n_updates        | 4459     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 108      |\n",
            "|    ep_rew_mean      | 99.5     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 234      |\n",
            "|    total_timesteps  | 19284    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.124    |\n",
            "|    n_updates        | 4570     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 104      |\n",
            "|    ep_rew_mean      | 95.3     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 204      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 236      |\n",
            "|    total_timesteps  | 19480    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.869    |\n",
            "|    n_updates        | 4619     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 104      |\n",
            "|    ep_rew_mean      | 95.5     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 208      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 240      |\n",
            "|    total_timesteps  | 19745    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.246    |\n",
            "|    n_updates        | 4686     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 103      |\n",
            "|    ep_rew_mean      | 94.8     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 212      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 243      |\n",
            "|    total_timesteps  | 20027    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0747   |\n",
            "|    n_updates        | 4756     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 102      |\n",
            "|    ep_rew_mean      | 93.6     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 216      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 246      |\n",
            "|    total_timesteps  | 20257    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.435    |\n",
            "|    n_updates        | 4814     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 104      |\n",
            "|    ep_rew_mean      | 95.2     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 220      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 252      |\n",
            "|    total_timesteps  | 20778    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.209    |\n",
            "|    n_updates        | 4944     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 104      |\n",
            "|    ep_rew_mean      | 95.5     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 224      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 256      |\n",
            "|    total_timesteps  | 21068    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.454    |\n",
            "|    n_updates        | 5016     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 105      |\n",
            "|    ep_rew_mean      | 96.7     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 228      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 261      |\n",
            "|    total_timesteps  | 21495    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.0949   |\n",
            "|    n_updates        | 5123     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 101      |\n",
            "|    ep_rew_mean      | 92.8     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 232      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 264      |\n",
            "|    total_timesteps  | 21831    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.717    |\n",
            "|    n_updates        | 5207     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 99.4     |\n",
            "|    ep_rew_mean      | 91       |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 236      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 270      |\n",
            "|    total_timesteps  | 22213    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.129    |\n",
            "|    n_updates        | 5303     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 103      |\n",
            "|    ep_rew_mean      | 94.1     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 240      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 278      |\n",
            "|    total_timesteps  | 22904    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.306    |\n",
            "|    n_updates        | 5475     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 99.5     |\n",
            "|    ep_rew_mean      | 90.9     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 244      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 281      |\n",
            "|    total_timesteps  | 23069    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.244    |\n",
            "|    n_updates        | 5517     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 99.4     |\n",
            "|    ep_rew_mean      | 90.7     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 248      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 285      |\n",
            "|    total_timesteps  | 23510    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.214    |\n",
            "|    n_updates        | 5627     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 93.1     |\n",
            "|    ep_rew_mean      | 84.7     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 252      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 287      |\n",
            "|    total_timesteps  | 23690    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.158    |\n",
            "|    n_updates        | 5672     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 87.7     |\n",
            "|    ep_rew_mean      | 79.9     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 256      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 292      |\n",
            "|    total_timesteps  | 24025    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.2      |\n",
            "|    n_updates        | 5756     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 89.3     |\n",
            "|    ep_rew_mean      | 81.6     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 260      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 297      |\n",
            "|    total_timesteps  | 24432    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.228    |\n",
            "|    n_updates        | 5857     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 89.1     |\n",
            "|    ep_rew_mean      | 81.1     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 264      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 301      |\n",
            "|    total_timesteps  | 24781    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.131    |\n",
            "|    n_updates        | 5945     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 89.8     |\n",
            "|    ep_rew_mean      | 81.3     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 268      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 309      |\n",
            "|    total_timesteps  | 25363    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.17     |\n",
            "|    n_updates        | 6090     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 92       |\n",
            "|    ep_rew_mean      | 83.1     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 272      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 315      |\n",
            "|    total_timesteps  | 25772    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.363    |\n",
            "|    n_updates        | 6192     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 92.4     |\n",
            "|    ep_rew_mean      | 83.4     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 276      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 319      |\n",
            "|    total_timesteps  | 25995    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.426    |\n",
            "|    n_updates        | 6248     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 93.7     |\n",
            "|    ep_rew_mean      | 84.8     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 280      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 325      |\n",
            "|    total_timesteps  | 26512    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.104    |\n",
            "|    n_updates        | 6377     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 94.7     |\n",
            "|    ep_rew_mean      | 85.4     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 284      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 333      |\n",
            "|    total_timesteps  | 27131    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.08     |\n",
            "|    n_updates        | 6532     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 98.6     |\n",
            "|    ep_rew_mean      | 88.4     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 288      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 341      |\n",
            "|    total_timesteps  | 27934    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.268    |\n",
            "|    n_updates        | 6733     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 97.9     |\n",
            "|    ep_rew_mean      | 87.7     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 292      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 347      |\n",
            "|    total_timesteps  | 28314    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.05     |\n",
            "|    n_updates        | 6828     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 98.8     |\n",
            "|    ep_rew_mean      | 88.8     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 296      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 351      |\n",
            "|    total_timesteps  | 28723    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.919    |\n",
            "|    n_updates        | 6930     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 105      |\n",
            "|    ep_rew_mean      | 93.4     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 300      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 363      |\n",
            "|    total_timesteps  | 29747    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.18     |\n",
            "|    n_updates        | 7186     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 107      |\n",
            "|    ep_rew_mean      | 95.4     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 304      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 368      |\n",
            "|    total_timesteps  | 30165    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.309    |\n",
            "|    n_updates        | 7291     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 108      |\n",
            "|    ep_rew_mean      | 96       |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 308      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 373      |\n",
            "|    total_timesteps  | 30505    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.483    |\n",
            "|    n_updates        | 7376     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 107      |\n",
            "|    ep_rew_mean      | 95.6     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 312      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 376      |\n",
            "|    total_timesteps  | 30751    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.27     |\n",
            "|    n_updates        | 7437     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 108      |\n",
            "|    ep_rew_mean      | 96.4     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 316      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 380      |\n",
            "|    total_timesteps  | 31069    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.624    |\n",
            "|    n_updates        | 7517     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 107      |\n",
            "|    ep_rew_mean      | 95.4     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 320      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 385      |\n",
            "|    total_timesteps  | 31475    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.62     |\n",
            "|    n_updates        | 7618     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 107      |\n",
            "|    ep_rew_mean      | 95.5     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 324      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 389      |\n",
            "|    total_timesteps  | 31808    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.536    |\n",
            "|    n_updates        | 7701     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 108      |\n",
            "|    ep_rew_mean      | 95.8     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 328      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 395      |\n",
            "|    total_timesteps  | 32278    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.179    |\n",
            "|    n_updates        | 7819     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 112      |\n",
            "|    ep_rew_mean      | 99.4     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 332      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 403      |\n",
            "|    total_timesteps  | 33028    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.707    |\n",
            "|    n_updates        | 8006     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 112      |\n",
            "|    ep_rew_mean      | 99.3     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 336      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 409      |\n",
            "|    total_timesteps  | 33423    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.3      |\n",
            "|    n_updates        | 8105     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 108      |\n",
            "|    ep_rew_mean      | 95.8     |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 340      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 412      |\n",
            "|    total_timesteps  | 33724    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.774    |\n",
            "|    n_updates        | 8180     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 114      |\n",
            "|    ep_rew_mean      | 100      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 344      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 420      |\n",
            "|    total_timesteps  | 34442    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.544    |\n",
            "|    n_updates        | 8360     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 117      |\n",
            "|    ep_rew_mean      | 103      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 348      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 430      |\n",
            "|    total_timesteps  | 35214    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.21     |\n",
            "|    n_updates        | 8553     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 125      |\n",
            "|    ep_rew_mean      | 109      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 352      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 441      |\n",
            "|    total_timesteps  | 36142    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.74     |\n",
            "|    n_updates        | 8785     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 131      |\n",
            "|    ep_rew_mean      | 115      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 356      |\n",
            "|    fps              | 81       |\n",
            "|    time_elapsed     | 453      |\n",
            "|    total_timesteps  | 37158    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.612    |\n",
            "|    n_updates        | 9039     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 132      |\n",
            "|    ep_rew_mean      | 115      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 360      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 458      |\n",
            "|    total_timesteps  | 37596    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.449    |\n",
            "|    n_updates        | 9148     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 136      |\n",
            "|    ep_rew_mean      | 118      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 364      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 467      |\n",
            "|    total_timesteps  | 38343    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.39     |\n",
            "|    n_updates        | 9335     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 138      |\n",
            "|    ep_rew_mean      | 121      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 368      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 477      |\n",
            "|    total_timesteps  | 39212    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.863    |\n",
            "|    n_updates        | 9552     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 141      |\n",
            "|    ep_rew_mean      | 122      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 372      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 485      |\n",
            "|    total_timesteps  | 39861    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.516    |\n",
            "|    n_updates        | 9715     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 150      |\n",
            "|    ep_rew_mean      | 130      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 376      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 498      |\n",
            "|    total_timesteps  | 40999    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.48     |\n",
            "|    n_updates        | 9999     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 151      |\n",
            "|    ep_rew_mean      | 130      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 380      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 506      |\n",
            "|    total_timesteps  | 41650    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.375    |\n",
            "|    n_updates        | 10162    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 150      |\n",
            "|    ep_rew_mean      | 129      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 384      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 513      |\n",
            "|    total_timesteps  | 42155    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.449    |\n",
            "|    n_updates        | 10288    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 150      |\n",
            "|    ep_rew_mean      | 129      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 388      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 522      |\n",
            "|    total_timesteps  | 42965    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.461    |\n",
            "|    n_updates        | 10491    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 151      |\n",
            "|    ep_rew_mean      | 129      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 392      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 528      |\n",
            "|    total_timesteps  | 43403    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.03     |\n",
            "|    n_updates        | 10600    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 159      |\n",
            "|    ep_rew_mean      | 135      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 396      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 542      |\n",
            "|    total_timesteps  | 44605    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.802    |\n",
            "|    n_updates        | 10901    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 155      |\n",
            "|    ep_rew_mean      | 132      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 400      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 549      |\n",
            "|    total_timesteps  | 45266    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.28     |\n",
            "|    n_updates        | 11066    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 159      |\n",
            "|    ep_rew_mean      | 135      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 404      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 560      |\n",
            "|    total_timesteps  | 46109    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.832    |\n",
            "|    n_updates        | 11277    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 169      |\n",
            "|    ep_rew_mean      | 142      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 408      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 575      |\n",
            "|    total_timesteps  | 47446    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.457    |\n",
            "|    n_updates        | 11611    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 177      |\n",
            "|    ep_rew_mean      | 148      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 412      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 587      |\n",
            "|    total_timesteps  | 48436    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.583    |\n",
            "|    n_updates        | 11858    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 181      |\n",
            "|    ep_rew_mean      | 151      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 416      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 596      |\n",
            "|    total_timesteps  | 49164    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.31     |\n",
            "|    n_updates        | 12040    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 190      |\n",
            "|    ep_rew_mean      | 158      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 420      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 611      |\n",
            "|    total_timesteps  | 50451    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.12     |\n",
            "|    n_updates        | 12362    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 193      |\n",
            "|    ep_rew_mean      | 160      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 424      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 619      |\n",
            "|    total_timesteps  | 51069    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.203    |\n",
            "|    n_updates        | 12517    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 191      |\n",
            "|    ep_rew_mean      | 159      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 428      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 623      |\n",
            "|    total_timesteps  | 51424    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.422    |\n",
            "|    n_updates        | 12605    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 186      |\n",
            "|    ep_rew_mean      | 154      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 432      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 625      |\n",
            "|    total_timesteps  | 51627    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.434    |\n",
            "|    n_updates        | 12656    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 155      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 436      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 632      |\n",
            "|    total_timesteps  | 52163    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.582    |\n",
            "|    n_updates        | 12790    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 193      |\n",
            "|    ep_rew_mean      | 160      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 440      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 642      |\n",
            "|    total_timesteps  | 53064    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.157    |\n",
            "|    n_updates        | 13015    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 190      |\n",
            "|    ep_rew_mean      | 158      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 444      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 648      |\n",
            "|    total_timesteps  | 53464    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.807    |\n",
            "|    n_updates        | 13115    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 191      |\n",
            "|    ep_rew_mean      | 158      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 448      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 657      |\n",
            "|    total_timesteps  | 54273    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.02     |\n",
            "|    n_updates        | 13318    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 191      |\n",
            "|    ep_rew_mean      | 158      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 452      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 668      |\n",
            "|    total_timesteps  | 55241    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 2.27     |\n",
            "|    n_updates        | 13560    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 193      |\n",
            "|    ep_rew_mean      | 159      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 456      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 683      |\n",
            "|    total_timesteps  | 56495    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.485    |\n",
            "|    n_updates        | 13873    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 196      |\n",
            "|    ep_rew_mean      | 161      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 460      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 692      |\n",
            "|    total_timesteps  | 57211    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 2.04     |\n",
            "|    n_updates        | 14052    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 195      |\n",
            "|    ep_rew_mean      | 160      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 464      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 700      |\n",
            "|    total_timesteps  | 57817    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.424    |\n",
            "|    n_updates        | 14204    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 192      |\n",
            "|    ep_rew_mean      | 157      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 468      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 706      |\n",
            "|    total_timesteps  | 58391    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.632    |\n",
            "|    n_updates        | 14347    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 192      |\n",
            "|    ep_rew_mean      | 157      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 472      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 715      |\n",
            "|    total_timesteps  | 59083    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.25     |\n",
            "|    n_updates        | 14520    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 192      |\n",
            "|    ep_rew_mean      | 157      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 476      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 729      |\n",
            "|    total_timesteps  | 60231    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.622    |\n",
            "|    n_updates        | 14807    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 194      |\n",
            "|    ep_rew_mean      | 159      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 480      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 738      |\n",
            "|    total_timesteps  | 61030    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.85     |\n",
            "|    n_updates        | 15007    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 194      |\n",
            "|    ep_rew_mean      | 159      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 484      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 744      |\n",
            "|    total_timesteps  | 61561    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.454    |\n",
            "|    n_updates        | 15140    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 193      |\n",
            "|    ep_rew_mean      | 158      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 488      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 753      |\n",
            "|    total_timesteps  | 62228    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.425    |\n",
            "|    n_updates        | 15306    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 193      |\n",
            "|    ep_rew_mean      | 158      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 492      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 758      |\n",
            "|    total_timesteps  | 62662    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.374    |\n",
            "|    n_updates        | 15415    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 186      |\n",
            "|    ep_rew_mean      | 153      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 496      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 765      |\n",
            "|    total_timesteps  | 63235    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.863    |\n",
            "|    n_updates        | 15558    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 188      |\n",
            "|    ep_rew_mean      | 154      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 500      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 775      |\n",
            "|    total_timesteps  | 64076    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.39     |\n",
            "|    n_updates        | 15768    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 153      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 504      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 783      |\n",
            "|    total_timesteps  | 64809    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.678    |\n",
            "|    n_updates        | 15952    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 177      |\n",
            "|    ep_rew_mean      | 146      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 508      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 788      |\n",
            "|    total_timesteps  | 65174    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.835    |\n",
            "|    n_updates        | 16043    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 173      |\n",
            "|    ep_rew_mean      | 142      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 512      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 795      |\n",
            "|    total_timesteps  | 65758    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 2.31     |\n",
            "|    n_updates        | 16189    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 172      |\n",
            "|    ep_rew_mean      | 142      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 516      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 803      |\n",
            "|    total_timesteps  | 66372    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.766    |\n",
            "|    n_updates        | 16342    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 172      |\n",
            "|    ep_rew_mean      | 141      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 520      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 817      |\n",
            "|    total_timesteps  | 67613    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.08     |\n",
            "|    n_updates        | 16653    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 170      |\n",
            "|    ep_rew_mean      | 141      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 524      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 823      |\n",
            "|    total_timesteps  | 68104    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.501    |\n",
            "|    n_updates        | 16775    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 173      |\n",
            "|    ep_rew_mean      | 143      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 528      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 831      |\n",
            "|    total_timesteps  | 68755    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.707    |\n",
            "|    n_updates        | 16938    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 183      |\n",
            "|    ep_rew_mean      | 151      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 532      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 845      |\n",
            "|    total_timesteps  | 69976    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.67     |\n",
            "|    n_updates        | 17243    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 187      |\n",
            "|    ep_rew_mean      | 153      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 536      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 856      |\n",
            "|    total_timesteps  | 70839    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.719    |\n",
            "|    n_updates        | 17459    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 194      |\n",
            "|    ep_rew_mean      | 158      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 540      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 874      |\n",
            "|    total_timesteps  | 72443    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.565    |\n",
            "|    n_updates        | 17860    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 203      |\n",
            "|    ep_rew_mean      | 165      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 544      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 889      |\n",
            "|    total_timesteps  | 73744    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.905    |\n",
            "|    n_updates        | 18185    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 206      |\n",
            "|    ep_rew_mean      | 167      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 548      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 903      |\n",
            "|    total_timesteps  | 74843    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.22     |\n",
            "|    n_updates        | 18460    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 203      |\n",
            "|    ep_rew_mean      | 164      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 552      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 911      |\n",
            "|    total_timesteps  | 75542    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.52     |\n",
            "|    n_updates        | 18635    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 199      |\n",
            "|    ep_rew_mean      | 161      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 556      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 922      |\n",
            "|    total_timesteps  | 76386    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.51     |\n",
            "|    n_updates        | 18846    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 205      |\n",
            "|    ep_rew_mean      | 166      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 560      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 937      |\n",
            "|    total_timesteps  | 77718    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.852    |\n",
            "|    n_updates        | 19179    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 204      |\n",
            "|    ep_rew_mean      | 164      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 564      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 942      |\n",
            "|    total_timesteps  | 78169    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.467    |\n",
            "|    n_updates        | 19292    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 207      |\n",
            "|    ep_rew_mean      | 167      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 568      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 953      |\n",
            "|    total_timesteps  | 79122    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.7      |\n",
            "|    n_updates        | 19530    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 212      |\n",
            "|    ep_rew_mean      | 171      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 572      |\n",
            "|    fps              | 82       |\n",
            "|    time_elapsed     | 967      |\n",
            "|    total_timesteps  | 80270    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.828    |\n",
            "|    n_updates        | 19817    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 203      |\n",
            "|    ep_rew_mean      | 165      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 576      |\n",
            "|    fps              | 83       |\n",
            "|    time_elapsed     | 970      |\n",
            "|    total_timesteps  | 80575    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.898    |\n",
            "|    n_updates        | 19893    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 215      |\n",
            "|    ep_rew_mean      | 173      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 580      |\n",
            "|    fps              | 83       |\n",
            "|    time_elapsed     | 993      |\n",
            "|    total_timesteps  | 82487    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.912    |\n",
            "|    n_updates        | 20371    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 178      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 584      |\n",
            "|    fps              | 83       |\n",
            "|    time_elapsed     | 1008     |\n",
            "|    total_timesteps  | 83778    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.574    |\n",
            "|    n_updates        | 20694    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 222      |\n",
            "|    ep_rew_mean      | 178      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 588      |\n",
            "|    fps              | 83       |\n",
            "|    time_elapsed     | 1016     |\n",
            "|    total_timesteps  | 84448    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.35     |\n",
            "|    n_updates        | 20861    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 229      |\n",
            "|    ep_rew_mean      | 184      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 592      |\n",
            "|    fps              | 83       |\n",
            "|    time_elapsed     | 1029     |\n",
            "|    total_timesteps  | 85608    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 3.88     |\n",
            "|    n_updates        | 21151    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 236      |\n",
            "|    ep_rew_mean      | 189      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 596      |\n",
            "|    fps              | 83       |\n",
            "|    time_elapsed     | 1043     |\n",
            "|    total_timesteps  | 86829    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.83     |\n",
            "|    n_updates        | 21457    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 235      |\n",
            "|    ep_rew_mean      | 188      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 600      |\n",
            "|    fps              | 83       |\n",
            "|    time_elapsed     | 1052     |\n",
            "|    total_timesteps  | 87581    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 2.22     |\n",
            "|    n_updates        | 21645    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 235      |\n",
            "|    ep_rew_mean      | 188      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 604      |\n",
            "|    fps              | 83       |\n",
            "|    time_elapsed     | 1060     |\n",
            "|    total_timesteps  | 88327    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.631    |\n",
            "|    n_updates        | 21831    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 236      |\n",
            "|    ep_rew_mean      | 188      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 608      |\n",
            "|    fps              | 83       |\n",
            "|    time_elapsed     | 1067     |\n",
            "|    total_timesteps  | 88776    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.956    |\n",
            "|    n_updates        | 21943    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 247      |\n",
            "|    ep_rew_mean      | 197      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 612      |\n",
            "|    fps              | 83       |\n",
            "|    time_elapsed     | 1086     |\n",
            "|    total_timesteps  | 90428    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.55     |\n",
            "|    n_updates        | 22356    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 250      |\n",
            "|    ep_rew_mean      | 199      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 616      |\n",
            "|    fps              | 83       |\n",
            "|    time_elapsed     | 1097     |\n",
            "|    total_timesteps  | 91359    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.909    |\n",
            "|    n_updates        | 22589    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 245      |\n",
            "|    ep_rew_mean      | 195      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 620      |\n",
            "|    fps              | 83       |\n",
            "|    time_elapsed     | 1106     |\n",
            "|    total_timesteps  | 92121    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.582    |\n",
            "|    n_updates        | 22780    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 251      |\n",
            "|    ep_rew_mean      | 200      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 624      |\n",
            "|    fps              | 83       |\n",
            "|    time_elapsed     | 1119     |\n",
            "|    total_timesteps  | 93251    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.2      |\n",
            "|    n_updates        | 23062    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 254      |\n",
            "|    ep_rew_mean      | 202      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 628      |\n",
            "|    fps              | 83       |\n",
            "|    time_elapsed     | 1129     |\n",
            "|    total_timesteps  | 94130    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.684    |\n",
            "|    n_updates        | 23282    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 249      |\n",
            "|    ep_rew_mean      | 198      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 632      |\n",
            "|    fps              | 83       |\n",
            "|    time_elapsed     | 1137     |\n",
            "|    total_timesteps  | 94871    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.04     |\n",
            "|    n_updates        | 23467    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 247      |\n",
            "|    ep_rew_mean      | 197      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 636      |\n",
            "|    fps              | 83       |\n",
            "|    time_elapsed     | 1146     |\n",
            "|    total_timesteps  | 95545    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.589    |\n",
            "|    n_updates        | 23636    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 239      |\n",
            "|    ep_rew_mean      | 191      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 640      |\n",
            "|    fps              | 83       |\n",
            "|    time_elapsed     | 1154     |\n",
            "|    total_timesteps  | 96314    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.22     |\n",
            "|    n_updates        | 23828    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 236      |\n",
            "|    ep_rew_mean      | 188      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 644      |\n",
            "|    fps              | 83       |\n",
            "|    time_elapsed     | 1166     |\n",
            "|    total_timesteps  | 97335    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.992    |\n",
            "|    n_updates        | 24083    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 232      |\n",
            "|    ep_rew_mean      | 185      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 648      |\n",
            "|    fps              | 83       |\n",
            "|    time_elapsed     | 1175     |\n",
            "|    total_timesteps  | 98065    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.24     |\n",
            "|    n_updates        | 24266    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 233      |\n",
            "|    ep_rew_mean      | 186      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 652      |\n",
            "|    fps              | 83       |\n",
            "|    time_elapsed     | 1184     |\n",
            "|    total_timesteps  | 98833    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 0.369    |\n",
            "|    n_updates        | 24458    |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 234      |\n",
            "|    ep_rew_mean      | 187      |\n",
            "|    exploration_rate | 0.02     |\n",
            "| time/               |          |\n",
            "|    episodes         | 656      |\n",
            "|    fps              | 83       |\n",
            "|    time_elapsed     | 1194     |\n",
            "|    total_timesteps  | 99753    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.001    |\n",
            "|    loss             | 1.29     |\n",
            "|    n_updates        | 24688    |\n",
            "----------------------------------\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "You have passed a tuple to the predict() function instead of a Numpy array or a Dict. You are probably mixing Gym API with SB3 VecEnv API: `obs, info = env.reset()` (Gym) vs `obs = vec_env.reset()` (SB3 VecEnv). See related issue https://github.com/DLR-RM/stable-baselines3/issues/1694 and documentation for more information: https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html#vecenv-api-vs-gym-api",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-fe960a241df3>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/dqn/dqn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;31m# Tuple obs are not supported by SB3, so we can safely do that check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    358\u001b[0m                 \u001b[0;34m\"You have passed a tuple to the predict() function instead of a Numpy array or a Dict. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m                 \u001b[0;34m\"You are probably mixing Gym API with SB3 VecEnv API: `obs, info = env.reset()` (Gym) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You have passed a tuple to the predict() function instead of a Numpy array or a Dict. You are probably mixing Gym API with SB3 VecEnv API: `obs, info = env.reset()` (Gym) vs `obs = vec_env.reset()` (SB3 VecEnv). See related issue https://github.com/DLR-RM/stable-baselines3/issues/1694 and documentation for more information: https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html#vecenv-api-vs-gym-api"
          ]
        }
      ],
      "source": [
        "config = {\n",
        "    \"observation\": {\n",
        "        \"type\": \"TimeToCollision\"\n",
        "    },\n",
        "    \"vehicles_count\": 50,\n",
        "    \"duration\": 120,\n",
        "    \"policy_frequency\": 5,\n",
        "    \"simulation_frequency\": 15\n",
        "}\n",
        "env = gym.make(\"highway-fast-v0\")\n",
        "env.configure(config)\n",
        "env.reset()\n",
        "\n",
        "model = DQN(\n",
        "    \"MlpPolicy\",\n",
        "    env,\n",
        "    learning_rate=1e-3,\n",
        "    buffer_size=50000,\n",
        "    learning_starts=1000,\n",
        "    batch_size=32,\n",
        "    tau=1.0,\n",
        "    gamma=0.99,\n",
        "    train_freq=4,\n",
        "    gradient_steps=1,\n",
        "    target_update_interval=1000,\n",
        "    exploration_fraction=0.1,\n",
        "    exploration_final_eps=0.02,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Definieren Sie einen Checkpoint-Callback\n",
        "checkpoint_callback = CheckpointCallback(save_freq=10000, save_path='./models/', name_prefix='dqn_model')\n",
        "\n",
        "# Trainieren Sie das Modell\n",
        "model.learn(total_timesteps=100000, callback=checkpoint_callback)\n",
        "\n",
        "# Speichern Sie das Modell\n",
        "model.save(\"dqn_highway\")\n",
        "\n",
        "# Laden Sie das Modell\n",
        "model = DQN.load(\"dqn_highway\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "kVoc_0EPRRf2",
        "outputId": "ffb5e4c8-0054-4601-b71b-6e2e75b4dc2d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-2934384d6fba>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gymnasium/wrappers/order_enforcing.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mResetNeeded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot call env.step() before calling env.reset()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gymnasium/wrappers/env_checker.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0menv_step_passive_checker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/highway_env/envs/common/abstract.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'human'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/highway_env/envs/common/abstract.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_render\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffscreen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/highway_env/envs/common/graphics.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"real_time_rendering\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"simulation_frequency\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mpygame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVE_IMAGES\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "env = gym.make(\"highway-fast-v0\", render_mode=\"human\", config=config)\n",
        "\n",
        "while True:\n",
        "  done = truncated = False\n",
        "  obs, info = env.reset()\n",
        "  while not (done or truncated):\n",
        "    action, _states = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, truncated, info = env.step(action)\n",
        "    env.render()\n",
        "\n",
        "env.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00787b19dd584aaa84c59ffdd727705d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bb6d3ca6796494c8b8b94b3f691325c",
            "placeholder": "​",
            "style": "IPY_MODEL_c8619f90e4e24dc2892446a079df904a",
            "value": "  0%"
          }
        },
        "0569add33f8b4f2385d269eb9b3c9e0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b16fb7a61964379a0047c95fbadfd0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ba00075524c4e2aa7fce4389baade81",
            "placeholder": "​",
            "style": "IPY_MODEL_508034f94a54419293b756a277324a85",
            "value": " 8/2001 [03:01&lt;9:12:37, 16.64s/episode]"
          }
        },
        "508034f94a54419293b756a277324a85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50f0cc04c9f2427bb5c13c97537b873e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d3ad70cae4f4dc9ab4df360ea0a98ee",
            "max": 2001,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5085c2eecb54a44b9693e9fc449fbd2",
            "value": 8
          }
        },
        "8bb6d3ca6796494c8b8b94b3f691325c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d3ad70cae4f4dc9ab4df360ea0a98ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ba00075524c4e2aa7fce4389baade81": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5085c2eecb54a44b9693e9fc449fbd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bfd047eee07a4f399c951c390f46d41e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00787b19dd584aaa84c59ffdd727705d",
              "IPY_MODEL_50f0cc04c9f2427bb5c13c97537b873e",
              "IPY_MODEL_3b16fb7a61964379a0047c95fbadfd0f"
            ],
            "layout": "IPY_MODEL_0569add33f8b4f2385d269eb9b3c9e0c"
          }
        },
        "c8619f90e4e24dc2892446a079df904a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
